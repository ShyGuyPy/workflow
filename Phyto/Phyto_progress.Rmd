---
title: "Phyto_progress"
author: "Luke Vawter"
date: "September 18, 2018"
output: html_document
---

Done: 
-get mmir working on my machine
-download CDER and ITIS data
-get pibi_notebook knitting error free on my machine
-read through the majority of pibi_notebook
-learn ggplot basics
-test use of custom function clean_up()
-take a look at scripts in project folder on Zach's old computer(up to date)
-download and work/play with virginia phytoplankton count and event data in Phyto
-download data through pibi_notebook script from url.root <- "http://datahub.chesapeakebay.net/api.JSON"
-do some exploratory data ananysis on phyto data to familiarize yourself both with the data and the EDA process
-edit typos
-send Claire pibi_notebook html by adding Pibi2 to H drive
-figure out where files are being output with fwrite: 
  1. "data/phytoplankton/cedr_phyto_taxa.csv"
  2. "data/phytoplankton/cedr_phyto_event.csv"
  3. "data/phytoplankton/cedr_phyto_station.csv"
  4. "data/water_quality/cedr_wq.csv"
  5. "data/itis/itis_hierarchy.csv"
-replace data_acquistion_cedr with data_input that pulls VA ODU data into phyto2
-get all data in phyto2 going to the right input(done...I think)
-ask Zach about 1) issue with dir.create when knitting pibi_notebook (also knit as start button?)
-figure out why directory/excel is not being generated in workflow when using Zach's code snippet(code snippet works fine outside of r markdown)
-produce an output (xls)
-figure out that loss of salzone data is the problem and search through the pipeline to find out where it's happening(in event prep, salzone letter conversion code, more details in phyto_notes)
-fix whatever is breaking the knit output with the modified sections(was code that was turned into headers rather than fully commented out)
-finish working through R For Data Science(through the parts relevant to phyto at least)
-learn to use extract_notebook_scripts.R to steamline testing process
-figure out where salzones are being lost(prep_events line 123)
-taxa_abund function is in mmir/R/composition.R
-add line in extract script at line 22 to create itit object
-resolve issue with code on line 123 of prep_events(commented out code that was meant to deal with salzone differences...)
-get an ibi score output for VA_ODU data :)
-evaluate ibi metric code to the point where you could effectively bug check it(excluding appendix, I think we can call this one done)
-output ibi.df

-track phyto.df to ibi.df(the primary dataframes throughout phyto):
   -phyto.df
   -bay.df(bay.sub)
   -bay.taxa
   -metrics.df
   -metrics.long(metrics.sub)
   -score_spring_p, score_spring_m, etc.
   -scores.df
   -ratings.df
   -ibi.df
   

Doing: 
-write/rewrite VA_ODU r markdown comments and save to H drive(H/Projects/Phytoplankton IBI)
-resolve station issue...may be losing station data at 3-day window code(bay.sub)---nope, they are being labelled NA
-re-work/re-build preprocessing section(pdepth not pycnocline)
-figure out why lat and long values in ibi.df output are varying with each output(so weird)


-re-write/fix any code that was non-functional with VA ODU data where possible

-look through Hadley Wickham's Advanced R guide
-look through r markdown the definitive guide
-take a year of cedr data 1990 and run it through the pipeline

-know the parts of MMIR and BIBI packages that are applicable to phyto and chessi_bibi



understand steps:

download data and dependencies

-downlaod CEDR data(from API, url.root <- "http://datahub.chesapeakebay.net/api.JSON"
-install packages(including MMIR)
-create vesctor for station data
-download all of the phytoplankton data from the CEDR API