---
title: "R practice"
author: "Luke Vawter"
date: "September 18, 2018"
output: html_document
---

factors in R:
https://swcarpentry.github.io/r-novice-inflammation/12-supp-factors/
not char or string,
they are integers and behave as such
```{r}
library(magrittr)

fruits <- factor(c("grape", "bananna", "grape", "bananna", "apple", "orange"))
#sets order of factor levels
fruits <- factor(fruits, levels = c("orange", "grape", "bananna", "apple"), ordered = TRUE)
levels(fruits)
nlevels(fruits)

fruits %>%
  trimws() %>%
  print()

```

trimws():
```{r}
library(magrittr)

thing <- " this is a test   "
print(trimws(thing))
#and again using pipes
thing %>% 
  trimws() %>%
  print()

```
playing with select, filter,     :
```{r}
library(magrittr)
library(readxl)
library(dplyr)


#creates project.dir, phyto directory object 
project.dir <- rprojroot::find_rstudio_root_file()

toy.df <- read_excel(file.path(project.dir, "data/jackie_data/Data 2013_4plus-phyto-metrics.xlsx"),
                         sheet = "DATA_4+biometrics",
                         skip = 1)

#colnames(toy.df)

new.toy.df <- toy.df %>%
  #include only those columns starting with s
  select(starts_with("s")) %>%
  
  #only include rows which fall within given ranges
  filter(SURVEY_ID <= 30867, SALINITY < 6) %>%
  #select(SURVEY_ID:SAMPLE_DATE) %>
  
  #arrange in descending order based on SURVEY_ID value
  arrange(desc(SURVEY_ID)) %>%
  print()

mutant.toy.df <- toy.df %>%
  
  mutate(nonsense=SECCHI/SALINITY) %>%
  print()
  
#also could do group_by()
```

```{r}
library(magrittr)

project.dir <- rprojroot::find_rstudio_root_file()

toy.df <- read_excel(file.path(project.dir, "data/jackie_data/Data 2013_4plus-phyto-metrics.xlsx"),
                         sheet = "DATA_4+biometrics",
                         skip = 1)

toy.df %>%
  select(PIBI_Rank) %>%
  print()


```

http://r4ds.had.co.nz/data-visualisation.html
working through "R for Data Science", a resource Zach linked.  Plenty of it I'm familiar with, but I'm finding my data scientist skills could use some work so I'm doing some review:
```{r}
library(ggplot2)
library(magrittr)
# cars.df <- ggplot2::mpg
# print(cars.df)

cars.columns.df <- ggplot2::mpg %>%
  colnames() %>%
  print()

ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = class, shape = drv))

ggplot(data = mpg) +
  geom_point(mapping = aes(x = cyl, y = hwy, color = class, shape = drv))




```
using str_replace_all func:
```{r}
library(ggplot2)
library(magrittr)

spaces <-c("hi here", "I'm tired","need a break")
snakes <- spaces %>%
  str_replace_all(" ", "_") %>%
  print()
```

show number of rows and coumns:
```{r}
nrow(mpg)
ncol(mpg)
```

how to apply an aesthetic to the whole plot
```{r}
library(ggplot2)

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = "blue")

```

facets can be used to break the above scaterplot into separate visualizations.  In this case the data is divided by the class of the car. What we end up with is clusters of data because car class(class) and engine size(displ) are tightly related.Also, we can see distinct sections of the downward trend of the data as engine size increases, hgihtlighting the negative relationship between engine size and highway miles per gallon(hwy).:
```{r}
library(ggplot2)


ggplot(data = mpg)+
  geom_point(mapping = aes(x=displ, y = hwy))+
  facet_wrap(~class, nrow = 2)

```


adding more than one geom:
```{r}
library(ggplot2)

ggplot(data = mpg)+
  geom_smooth(mapping = aes(x=displ, y= hwy,linetype=drv, color=drv))+
  geom_point(mapping = aes(x=displ, y= hwy, color=drv))
```

gloabl geom plotting:
```{r}
ggplot(data=mpg, mapping = aes(x=displ,y=hwy))+
  geom_line(color="blue")+
  geom_point(mapping =aes(color = class))+
  geom_smooth()
  
```

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + 
  geom_point() + 
  geom_smooth(se=FALSE)
```

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy))+
  geom_point(mapping=aes(color=drv))+
  geom_smooth(mapping=aes(linetype=drv),se=FALSE)+
  coord_flip()
```

summary I don't fully get or see the value of but here it is:
```{r}
library(ggplot2)
ggplot(data= mpg)+
  stat_summary(
    mapping = aes(x = displ, y = hwy),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```


position values of identity, dodge, and fill(below) alter the presentation of the data:
```{r}
ggplot(data = diamonds, mapping = aes(x=cut, fill = clarity))+
  geom_bar(alpha = 3/5, position= "fill" )
```

The use of jitter in a scatterplot fixes the problem of overplotting cuased by rounding of values.  Here we can see the clustering various points(such as position 4.7, 5 or 2.8,20).  The desnity of the blob gies us a sense of how many points land at approximately the same axis point
```{r}
ggplot(data=mpg)+
  geom_point(mapping=aes(x=displ,y=hwy), position ="jitter")
```

coxcomb chart:
```{r}
library(ggplot2)

assigned <- ggplot(data=mpg, mapping = aes(x=drv, fill =drv))+
  geom_bar(width=1)+
  theme(aspect.ratio = 1)+
  labs(x = NULL, y =NULL)


assigned + coord_polar() #+ coord_flip()
  
```

"The grammar of graphics is based on the insight that you can uniquely describe any plot as a combination of a dataset, a geom, a set of mappings, a stat, a position adjustment, a coordinate system, and a faceting scheme."


```{r}
graph_components <- c("dataset", "geom", "set of mappings", "a stat", "postion", "coordinate system", "faceting scheme" )


# for (component in graph_components){
#   print(component)
# }
```

some basic R,; seq() is a function that constructs a sequence between(inclusive) the two numbers passed to it:
```{r}
seq(1,25)
```

dplyr exercises and I need the practice:
```{r}
library(nycflights13)
library(tidyverse)

#wrapped in () to both print and assign to variable
(my_flight_data <- flights %>%
  #only showing rows where dep_delay value is greater than 20
  filter(dep_delay < -20) %>%
  #only showing columns cep_delay and arr_time
  select(dep_delay,arr_time))
  #something else
  
  
```

dealing with NA values.  is.na() can be used to reference such values:
```{r}
things.df <- tibble(stuff = c(NA,2,NA))

things.df %>%
  filter(is.na(things.df) | things.df<3)

```

playing with for loops:
```{r}
library(tidyverse)
library(dplyr)
date <- "1/1/1"

id_df <- c(1,2,3)
date_df <- c("1/1/1","2/2/2","3/3/3")
value_df <- c(12,18,10)
data.df <- data.frame(id_df,date_df, value_df)
print(data.df)

for (i in 2:nrow(data.df)){
  case_when(
    date_df[i] != "1/1/1" ~ print(paste0("nope ", value_df[i])),
    date_df[i] == "1/1/1" ~ print(paste0("yep ", value_df[i]))#"yep")
  )
}

  
             
             
```
I think the above code has an issue with how I constructed the dataframe.  Will revisit but it's not my primary issue atm.

```{r}
library(readxl)

path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p)

#print(my_data_p)
#print(nrow(my_data_p))
mystery <- {
for(i in my_data_p$date){
  
  #print(i)
  if(as.character(i) == "1998-10-06"){print(my_data_p$p_percent_normal[which(my_data_p$date == i)])}#print(my_data_p$p_percent_normal[4])}
 
  
  

   #print(my_data_p[[i]])
}}

```

convert date format:
```{r}
#convert from "10/1/1998" to "1998/10/01"
#date <- "10/1/1998"
date <- "5/5/1981"
month="-"
day="-"
#day_single="-0"
year =""

#iterates over string date
for(i in strsplit(date,"")[[1]]){ 
  #for single digit month values
  if (i == "/" && nchar(month) <3){month <- paste0(substring(month, 1, 1), 0, substring(month,2,2))}
  #adds value to month until month has enough characters
  if (i != "/" && nchar(month) < 3) {month <- paste0(month,i)}


  
  #adds value to day until day is long enough
  else if (i != "/" && nchar(day) <3) {day <- paste0(day,i)}
  #adds a 0 in front of day value if day is only one digit
  else if (i == "/" && nchar(month) ==3 && nchar(day) >1 && nchar(day) <3) {day <- paste0(substring(day, 1, 1), 0, substring(day,2,2))}#day <- paste0(day_single,day[2])}
  #adds value to years until it is long enough
  else if (i != "/" && nchar(day) ==3 && nchar(month) == 3 && nchar(year)<4){year<- paste0(year,i)}
  
  #else if (i == "/"){}
  # case_when(
  #   i != "/"~print("no tilde"),
  #   i == "1"~print("bingo")
#date2 <- paste0(year,month,day)
#)
}
date2 <- paste0(year,month,day)
print(date2)
```
and it works. now to add it to shiny_test_app2
...and realize I've written it to convert in reverse...
so the other way now:


```{r}
#convert from "1998-10-01" to "10/1/1998"
date <- "1990-05-17"
#date <- paste0(date,"-")
month=""
day="/"
day_single= FALSE
month_single=FALSE
year ="/"

#iterates over string date
for(i in strsplit(date,"")[[1]]){
  
  if (i != "-" && nchar(year) < 5){year<- paste0(year,i)}
  
  else if (i == "0" && nchar(month) <1){month_single = TRUE}
  else if (i != "-" && nchar(month) <1){month <- paste0(month,i)}
  else if (i != "-" && nchar(month) <2 && month_single == FALSE){month <- paste0(month,i)}
  
  else if (i == "0" && nchar(day) <2) {day_single = TRUE}
  else if (i != "-" && nchar(day) <2) {day <- paste0(day,i)}
  else if (i != "-" && nchar(day) <3 && day_single == FALSE) {day <- paste0(day,i)}

}
date2 <- paste0(month,day, year)
print(date2)
```

bug checking:
```{r}
library(readxl)
library(dplyr)


#grabs data
path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p, stringsAsFactors = FALSE)

#converts date format
date_func <- function(date){
  date <- as.character(date)
  date <- paste0("",date,"")
  month=""
  day="/"
  day_single= FALSE
  month_single=FALSE
  year ="/"
  
  #iterates over string date
  for(i in strsplit(date,"")[[1]]){
    
    if (i != "-" && nchar(year) < 5){year<- paste0(year,i)}
    
    else if (i == "0" && nchar(month) <1){month_single = TRUE}
    else if (i != "-" && nchar(month) <1){month <- paste0(month,i)}
    else if (i != "-" && nchar(month) <2 && month_single == FALSE){month <- paste0(month,i)}
    
    else if (i == "0" && nchar(day) <2) {day_single = TRUE}
    else if (i != "-" && nchar(day) <2) {day <- paste0(day,i)}
    else if (i != "-" && nchar(day) <3 && day_single == FALSE) {day <- paste0(day,i)}
    
  }
  date <- paste0(month,day, year)
  return(date)
}

test_date = 1998-10-04
print(date_func(test_date))

p_data_percent <-
for(i in my_data_p$date){

                    case_when(
                   as.character(i) == as.character( date_func(1998-10-04))
                      ~"good"#my_data_p$p_percent_normal[which(my_data_p$date == i)]
                    )
  
}

print(p_data_percent)
print(my_data_p$p_percent_normal[which(my_data_p$date == "1998-10-04")])

# for(i in my_data_p$date){
#   
#   #print(i)
#   if(as.character(i) == "1998-10-04"){print(my_data_p$p_percent_normal[which(my_data_p$date == i)])}#print(my_data_p$p_percent_normal[4])}
```


```{r}
library(readxl)
library(dplyr)


#grabs data
path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p)

# for(i in my_data_p$p_percent_normal){
#   print(typeof(i))
# }

# for(i in my_data_p$date){
#   print(typeof(i))
# }
```

```{r}
thing0 <- 1-2-3 
thing <- as.character(1-2-3)
thing2 <- "1-2-3"
thing3 <- as.double(1-2-3)

print(nchar(thing))
print(nchar(thing2))
print(thing)
print(thing0)
print(thing3)

```

R is running date values with "-" as math operations

Interesting...but discontinuing because a different approach is needed for integration into 2018DEX.

r for Data Science 5.3, 5.4:
```{r}
library(dplyr)

path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
                if( .Platform$OS.type == "unix" ) {
                  path_p <- "/Users/lukevawter/Desktop/R/2018drex/input/ts/state/i_a1b/va_shenandoah_p.csv"
                }
my_data_p = data.table::fread(path_p)
print(my_data_p)


mdp_trimmed <- my_data_p %>%
  #arrange(my_data_p$p_percent_normal) %>%
  select(-date) %>%
  select(-V3,-V4)

  
mdp_trimmed %>%
  transmute(double = my_data_p$p_percent_normal * 2) %>%
  mutate(triple = my_data_p$p_percent_normal * 3)

  


```


```{r}
library(nycflights13)

flights_sml <- select(flights,
                      year:day,
                      ends_with("delay"),
                      distance,
                      air_time
                      )

flights_mut <- flights_sml %>%
  mutate(gain = dep_delay - arr_delay,
       speed = distance / air_time * 60)

flights_mut %>%
  select(gain, speed)
```

R for Data Science 5.5:
```{r}
library(nycflights13)

flights %>%
  transmute(dep_time, hour = dep_time %/% 100,
            minutes = dep_time %% 100)
```

and a bit of python review just because I feel like I'm getting rusty:
```{python}
test_var = 517 

remains_2= test_var % 100
remains_1= (test_var - remains_2) / 100
print("{}:{}".format(remains_1,remains_2))
```

R for Data Science 5.6 using summarise():
```{r}
library(nycflights13)

by_day <- flights %>%
  group_by(year, month, day) #%>%

by_day %>%
  summarise( delay = mean(dep_delay, na.rm=TRUE))

# by_day <- group_by(flights, year, month, day)
# summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```
na.rm overrieds the rule that any input with missing values will generate a missing value(NA).  If we don't want those NA's in our output we include na.rm in summarise.

```{r}
library(ggplot2)

not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)

delays %>% 
  filter(n > 20) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)

```



```{r}
library(readxl)

path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p)

#print(my_data_p)
#print(nrow(my_data_p))
cake = "hello"
for(i in my_data_p$date){
  if(as.character(i) == "1998-10-04"){cake<-my_data_p$p_percent_normal[which(my_data_p$date == i)]}#print(my_data_p$p_percent_normal[4])}
}
print(cake) 
print(typeof(cake))
  

   #print(my_data_p[[i]])

```

```{r}
library(shiny)
path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p)

p_data_percent <- eventReactive(test_date$test_date_value, {
  for(i in my_data_p$date){
    case_when(
      as.character(i) == as.character(test_date$test_date_value)~ my_data_p$p_percent_normal[which(my_data_p$date == i)])
                    
                  }})

                
precip_value<-eventReactive(test_date$test_date_value,{#a_index,{
                case_when(
                  p_data_percent() <= .0 ~ "background-color:purple", #"#000000",
                  p_data_percent() > .0 && p_data_percent() <= .20 ~ red,#"background-color:red", #"#cc3300",
                  p_data_percent() > .20 && p_data_percent() <= .40 ~ orange,#"background-color:orange",  #"#ff9966",
                  p_data_percent() > .40 && p_data_percent() <= .60 ~ yellow,#"background-color:yellow",  #"#ffcc00",
                  p_data_percent() > .60 && p_data_percent() <= .80 ~ green,#"background-color:green", #"#99cc33",
                  p_data_percent() > .80 && p_data_percent() < 1 ~  navy, #"background-color:navy" #"#339900"
                  TRUE ~ black
                )})

print(p_data_percent)
print(precip_value)
```


```{r}
library(readxl)

path_p <- "C:\\Users\\icprbadmin\\Documents\\R\\2018drex\\input\\ts\\state\\i_a1b\\va_shenandoah_p.csv"
my_data_p = read.csv(path_p)


find_date <- function(col_date, col_val ){
for(i in col_date){
  if(as.character(i) == "1998-10-06"){our_value <- (col_val[which(col_date == i)])}
}
  return(our_value)}

print(find_date(my_data_p$date, my_data_p$p_percent_normal))
```

```{r}
nums <- c(1,2,3)

(2 %in% nums)
(4 %in% nums)
```

```{r}
library(magrittr)
library(dplyr)
project.dir <- rprojroot::find_rstudio_root_file()

col.class.vec <- c("samplenumber" = "character",
                   "tsn" = "character",
                   "speccode" = "character")

taxa.raw <- data.table::fread(file.path(project.dir, "data/phytoplankton/cedr_phyto_taxa.csv"),
                            data.table = FALSE,
                            colClasses = col.class.vec,
                            na.strings = "") %>% 
  mutate(sampledate = as.Date(sampledate))

bay.df <- taxa.raw %>% 
  filter(layer %in% c("ap", "wc")) %>% 
  distinct() %>% 
  mutate(month = month(sampledate),
         season = case_when(
           month %in% c(3, 4, 5) ~ "spring",
           month %in% c(7, 8, 9) ~ "summer",
           TRUE ~ "remove"
         )) %>% 
  filter(season %in% c("spring", "summer"))
```

this is how rename works(requires plyr apparently):
```{r}
library(dplyr)
library(plyr)

my_vec <- c("a" = 1, "b" = 2, "c" = 4)
my_vec

my_vec <- rename(my_vec, c("a"="alpha","b"="bravo","c"="charlie"))
my_vec

```

````{r}
library(magrittr)
library(dplyr)
library(ggplot2)

clean_string <- function(x) {
  x %>% 
    stringr::str_trim() %>% 
    tolower() %>% 
    stringr::str_replace_all("\\s+", " ") %>% 
    stringr::str_replace_all(" ", "_") %>%  
    if_else(. == "", as.character(NA), .)
}

clean_up <- function(x) {
  x %>% 
    rename_all(clean_string) %>% 
    mutate_if(is.character, funs(clean_string))%>% 
    distinct()
}

project.dir <- rprojroot::find_rstudio_root_file()

old.salzone <- readxl::read_excel(file.path(project.dir, "data/jackie_data/JMJ_PIBI_Salzone_Data.xlsx"),
                                  sheet = "DataHub_Phytoplankton_Events_22")#was "JMJ Salzone+Scores"
colnames(old.salzone)

clean_zone <- clean_up(old.salzone) 

ggplot(data = clean_zone, mapping = aes(x = totaldepth, color= salzone)) +
  geom_freqpoly(binwidth = 1, na.rm = TRUE )

ggplot(data=clean_zone, mapping = aes(x = totaldepth, color= pdepth))+
  geom_histogram(binwidth = 1, na.rm = TRUE )#+
  #coord_cartesian(ylim= c(0,200))  #used to zoom in

explore_val <- clean_zone %>%
  filter(totaldepth > 33 | totaldepth <2) %>%
  select(sampletime, longitude, latitude, salzone)
  #select()
rare_val

#as far as I know these are not values that should be excluded in this way.  I'm only using them for practice
clean_zone.nona <- clean_zone %>%
  mutate(totaldepth = ifelse(totaldepth<2 | totaldepth>33, NA, totaldepth)) %>%
  arrange(totaldepth) 

print(clean_zone.nona %>%
  select(totaldepth))
  
```


```{r}
library(readxl)
library(dplyr)

my_data_p <-data.table::fread(paste("test_data.csv", sep = ""))
print(head(my_data_p,2))
print(typeof(my_data_p$date[1]))
print(typeof(my_data_p$date[2]))

```

R for Data science 7.5 plus incorporating some of Zach's phyto code:
```{r}
library(magrittr)
library(dplyr)
library(ggplot2)

clean_string <- function(x) {
  x %>% 
    stringr::str_trim() %>% 
    tolower() %>% 
    stringr::str_replace_all("\\s+", " ") %>% 
    stringr::str_replace_all(" ", "_") %>%  
    if_else(. == "", as.character(NA), .)
}

clean_up <- function(x) {
  x %>% 
    rename_all(clean_string) %>% 
    mutate_if(is.character, funs(clean_string))%>% 
    distinct()
}

project.dir <- rprojroot::find_rstudio_root_file()

old.salzone <- readxl::read_excel(file.path(project.dir, "data/jackie_data/JMJ_PIBI_Salzone_Data.xlsx"),
                                  sheet = "DataHub_Phytoplankton_Events_22")#was "JMJ

colnames(old.salzone)

clean_zone <- clean_up(old.salzone) 

print(tail(clean_zone,2))
print(clean_zone[1,5])

zone.vec <- sort(unique(clean_zone$salzone))
min.zone <- zone.vec[1]
max.zone <- zone.vec[length(zone.vec)]

ggplot(data=clean_zone, mapping = aes(salzone, totaldepth)) +
  scale_y_continuous(limits = c(0,35))+
  annotate("rect", xmin=min.zone, xmax=max.zone, ymin =0, ymax = 10,fill= "red", alpha=.25)+
  annotate("rect", xmin=min.zone, xmax=max.zone, ymin =10, ymax =25 ,fill= "yellow", alpha=.25)+
  annotate("rect", xmin=min.zone, xmax=max.zone, ymin =25, ymax = 35,fill= "green", alpha=.25)+
  geom_boxplot()
```



```{r}
library(readxl)
library(dplyr)


my_data_p <-data.table::fread(paste("handmade_test_data.csv", sep = ""))
print(head(my_data_p,6))
print(typeof(my_data_p$date[1]))
print(typeof(my_data_p$date[2]))


todays_date = "10/5/1998"#"1998-10-05"


date_func <- function(col_date, col_val, date_today ){
  our_value <- 0
  for(i in col_date){
    if(i == as.character(date_today)){our_value <- (col_val[which(col_date == i)])}
  }
  return(our_value)}

date_func(my_data_p$date, my_data_p$p_percent_normal, todays_date)

```

```{r}
library(dplyr)

df = read.csv("./cedr_phyto_station.csv", stringsAsFactors = F)
print(df$latitude)

df$latitude <- as.numeric(df$latitude)
df$longitude <- as.numeric(df$longitude)
```


```{r}
library(magrittr)
library(ggplot2)

ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = class, shape = drv))+
  coord_cartesian(xlim =c(5, 20), ylim = c(0, 50))
```

use of str_detect:
```{r}
#required pacakge fro using str_detect
library(stringr)

my_str <- "orangeapplebananna"
str_detect(my_str, "apple")
str_detect(my_str, "pear")

```

```{r}
elements.vec <- c(1,2,3,8)
current.vec <- c(2,4,5,6)

if(any(!nums %in% unique(nums2))) {print(nums[!nums %in% unique(nums2)])}
#if(any(!nums %in% nums2)){print(!nums)}



```

```{r}
library(stringr)
p = "today's date is"
m = "10/10/1910"
#str_c(p,m, sep= " ")
str_pad(str_c("today's date is",m, sep= " "), width = 30, side = "right", pad= " ")


```



12/3/18
some dplyr practice for future work on phyto, chessie_bibi and mmir
https://www.youtube.com/watch?v=jWjqLW-u3hc
```{r}
library(dplyr)
library(readxl)
library(data.table)

project.dir <- rprojroot::find_rstudio_root_file()

print(project.dir)


phyto_practice.df <- data.table::fread(file.path(project.dir, 
                                                 "data/phytoplankton2/VA_ODU_phyto_event.csv"),
                            data.table = FALSE,
                            #colClasses = col.class.vec,
                            na.strings = "")

pp.df <- phyto_practice.df

pp.df %>%
  tally(sort=TRUE)

pp_changed.df <- pp.df %>%
  select(pdepth, totaldepth) %>%
  arrange(desc(pdepth)) %>%
  mutate(deep_p = pdepth >=20)

#https://www.youtube.com/watch?v=f0U74ZvLfQo

# make the item at row 2 column 2 NA
pp_changed.df[2,2]<-NA

final.df <- pp_changed.df%>%
  summarize(measurevalue = mean(pdepth, na.rm=TRUE))


```



https://www.datacamp.com/community/tutorials/r-tutorial-apply-family
```{r}
apple <- matrix(rnorm(18), nrow = 3, ncol = 6)
#print(apple)


#to apply mean calculation to each set of column values
apply(apple, 2, mean)

#to apply mean calculation to each set of row values
apply(apple, 1, mean)

#trimmed <- apply(apple[,-c(1,2)],2,mean)
```

to test RET,TF,LE station issue fix
```{r}
library(dplyr)
library(readxl)
library(data.table)

project.dir <- rprojroot::find_rstudio_root_file()

events_test.df <- data.table::fread(file.path(project.dir, 
                                                 "data/phytoplankton2/VA_ODU_phyto_event.csv"),
                            data.table = FALSE,
                            #colClasses = col.class.vec,
                            na.strings = "")

stations_test.df <- events_test.df %>%
  select(station) %>%
  distinct()

events_test.df <- events_test.df%>%

mutate(salzone_test = case_when(
    events_test.df$station %in% c("tf3.3","tf4.2","tf5.5")~ "F",
    #events_test.df$station == starts_with("cb")~ "good",
    events_test.df$station %in% c("ret3.1","ret4.3","ret3.1")~ "O",
    events_test.df$station %in% c("le3.6","le5.2","le5.4","le5.5-w")~ "P",
    TRUE~"bogus"

  )
  )

    

```

```{r}
library(dplyr)
library(readxl)
library(data.table)

project.dir <- rprojroot::find_rstudio_root_file()

taxa.df <- data.table::fread(file.path(project.dir, 
                                                 "data/phytoplankton2/VA_ODU_phyto_taxa.csv"),
                            data.table = FALSE,
                            #colClasses = col.class.vec,
                            na.strings = "")



id <- c(1,2,3)
date <- c("1/1/1","2/2/2","3/3/3")
name <- c("ted","fred", "dave")
value <- c(12,5,10)
data.df <- data.frame(id, date, value, name)

n.df <- data.df%>%
  group_by_at(vars(-value)) %>% 
  summarise(value=mean(value)) %>%
  ungroup()


#count(data.df$name == 23)

test.df <- data.df %>% 
  group_by_at(vars(-value)) %>%
  summarize(value = sum(value)) %>%
  ungroup()

find.df <- data.df %>%
  filter(grepl("ed", name))

# test2.df <- taxa.df %>% 
#   group_by_at(vars(-reportingvalue)) #%>%
  # summarize(reportingvalue2 = sum(reportingvalue)) %>%
  # ungroup()


```


this is salzone calculation but without 3 day
```{r}
library(dplyr)
library(readxl)
library(data.table)
library(tidyr)

project.dir <- rprojroot::find_rstudio_root_file()
wq.raw <- data.table::fread(file.path(project.dir, "data/water_quality/cedr_wq.csv"),
                            data.table = FALSE,
                           na.strings = c("")) %>% 
  filter(is.na(problem),
         parameter %in% c("chla", "doc", "pheo", "salinity"))

wq.df <- wq.raw %>% 
  mutate(sampledate = as.Date(sampledate))

wq.df <- wq.df %>% 
  select(station, source, sampledate, samplereplicatetype,
         depth, layer, 
         #pycnocline, upperpycnocline, lowerpycnocline,
         parameter, measurevalue) %>% 
  distinct()

wq.df <- wq.df %>% 
  filter(layer == "s", 
         parameter == "chla") %>% 
  unite(parameter, c("layer", "parameter"), remove = FALSE) %>% 
  bind_rows(wq.df)

chla <- wq.df %>%
  filter(parameter=="chla")

#get event.df
events.df <- data.table::fread(file.path(project.dir, "data/phytoplankton2/VA_ODU_phyto_event.csv"
                                         ),
                            data.table = FALSE,
                            na.strings = "")

#get pdepth from event.df
pdepth.df <- events.df %>% 
  filter(layer %in% c("ap", "wc")) %>% 
  mutate(sampledate = as.Date(sampledate)) %>% 
  select(station, sampledate, pdepth) %>% 
  dplyr::distinct()

#filter out below pdepth samples in wq.df
wq.df <- left_join(wq.df, pdepth.df, by = c("station", "sampledate"))
wq.df <- wq.df %>% 
  filter(depth <= pdepth) #%>% 
  
s_chla.df <- wq.df %>%
  filter(parameter=="s_chla")


di_doc.df <- wq.df %>%
  filter(parameter=="doc")

di_chla <- wq.df %>%
  filter(parameter == "chla")

di_salinity <- wq.df %>%
  filter(parameter == "salinity")

di_pheo <- wq.df %>%
  filter(parameter == "pheo")

avg_sal.df <- di_salinity %>%

  group_by(station, sampledate) %>%
  mutate(avg_sal = mean(measurevalue, na.rm = TRUE)) %>%
  ungroup()

avg_salzone.df <- avg_sal.df %>%

  mutate(salzone = case_when(
    measurevalue >0 & measurevalue <= 0.5 ~ "F",
    measurevalue > .5 &  measurevalue <= 5 ~ "O",
    measurevalue > 5 & measurevalue <= 18 ~ "M",
    measurevalue > 18~ "P")
  )
```

```{r}
library(dplyr)
library(readxl)
library(data.table)
library(tidyr)

project.dir <- rprojroot::find_rstudio_root_file()

wq.raw <- data.table::fread(file.path(project.dir, "data/water_quality/cedr_wq.csv"),
                            data.table = FALSE,
                           na.strings = c("")) %>% 
  filter(is.na(problem),
         parameter %in% c("chla", "doc", "pheo", "salinity"))


events.df <- data.table::fread(file.path(project.dir, "data/phytoplankton2/VA_ODU_phyto_event.csv"
                                         ),
                            data.table = FALSE,
                            na.strings = "")

wq.df <- wq.raw %>% 
  mutate(sampledate = as.Date(sampledate))

#3 day prep
events.sub <- events.df %>% 
  select(station, sampledate) %>% 
  distinct() %>% 
  mutate(sampledate = as.Date(sampledate)) %>%
  mutate(lower_date = sampledate - lubridate::days(3),
         upper_date = sampledate + lubridate::days(3))

library(parallel)
n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl = cl, varlist = c("wq.df", "events.sub"))
clusterEvalQ(cl, c(library(dplyr))) %>% invisible()

env.df <- parLapply(cl, 1:nrow(events.sub), function(row.i) {
  
  sub.df <- slice(events.sub, row.i)
  #----------------------------------------------------------------------------
  sub.env <- wq.df %>% 
    filter(station == sub.df$station,
           date >= sub.df$lower_date,
           date <= sub.df$upper_date)
  #----------------------------------------------------------------------------
  if (nrow(sub.env) == 0) return(data.frame(
    station = NA,
    date = NA,
    parameter = NA,
    measurevalue = NA
  ))
  #----------------------------------------------------------------------------
  final.df <- sub.env %>% 
    mutate(date_diff = date - sub.df$sampledate,
           abs_date_diff = abs(date_diff),
           sampledate = sub.df$sampledate) %>% 
    filter(abs_date_diff == min(abs_date_diff))
  #----------------------------------------------------------------------------
  if (nrow(final.df) > 1) {
    final.df <- final.df %>% 
      filter(date == min(date))
  }
  #----------------------------------------------------------------------------
  return(final.df)
}) %>% 
  bind_rows() %>% 
  filter(!is.na(station))

stopCluster(cl)
```

```{r}
library(dplyr)
library(readxl)
library(data.table)
library(tidyr)

project.dir <- rprojroot::find_rstudio_root_file()

wq.raw <- data.table::fread(file.path(project.dir, "data/water_quality/cedr_wq.csv"),
                            data.table = FALSE,
                           na.strings = c("")) %>% 
  filter(is.na(problem),
         parameter %in% c("chla", "doc", "pheo", "salinity"))


events.df <- data.table::fread(file.path(project.dir, "data/phytoplankton2/VA_ODU_phyto_event.csv"
                                         ),
                            data.table = FALSE,
                            na.strings = "")

wq.df <- wq.raw %>% 
  mutate(sampledate = as.Date(sampledate))

#3 day prep
events.sub <- events.df %>% 
  select(station, sampledate) %>% 
  distinct() %>% 
  mutate(sampledate = as.Date(sampledate)) %>%
  mutate(lower_date = sampledate - lubridate::days(3),
         upper_date = sampledate + lubridate::days(3))

library(parallel)
n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl = cl, varlist = c("wq.df", "events.sub"))
clusterEvalQ(cl, c(library(dplyr))) %>% invisible()

env.df <- parLapply(cl, 1:nrow(events.sub), function(row.i) {
  
  sub.df <- slice(events.sub, row.i)
  #----------------------------------------------------------------------------
  # sub.env <- wq.df %>% 
  #   filter(station == sub.df$station,
  #          date >= sub.df$lower_date,
  #          date <= sub.df$upper_date)
})
```

```{r}
library(parallel)

bay.sub <- bay.df %>% 
  select(station, sampledate) %>% 
  distinct() %>% 
  mutate(lower_date = sampledate - lubridate::days(3),
         upper_date = sampledate + lubridate::days(3))

n.cores <- detectCores() - 1
cl <- makeCluster(n.cores)
clusterExport(cl = cl, varlist = c("wq.df", "bay.sub"))
clusterEvalQ(cl, c(library(dplyr))) %>% invisible()


env.df <- parLapply(cl, 1:nrow(bay.sub), function(row.i) {

  sub.df <- slice(bay.sub, row.i)
  #----------------------------------------------------------------------------
  sub.env <- wq.df %>% 
    filter(station == sub.df$station,
           date >= sub.df$lower_date,
           date <= sub.df$upper_date)
  #----------------------------------------------------------------------------
  if (nrow(sub.env) == 0) return(data.frame(
    station = NA,
    date = NA,
    parameter = NA,
    measurevalue = NA
  ))
  #----------------------------------------------------------------------------
  final.df <- sub.env %>% 
    mutate(date_diff = date - sub.df$sampledate,
           abs_date_diff = abs(date_diff),
           sampledate = sub.df$sampledate) %>% 
    filter(abs_date_diff == min(abs_date_diff))
  #----------------------------------------------------------------------------
  if (nrow(final.df) > 1) {
    final.df <- final.df %>% 
      filter(date == min(date))
  }
  #----------------------------------------------------------------------------
  return(final.df)
}) %>% 
  bind_rows() %>% 
  filter(!is.na(station))

stopCluster(cl)
#closeAllConnections()
```

